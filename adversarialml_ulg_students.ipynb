{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Adversarial Machine Learning\n",
    "\n",
    "*SE2 Current Topics in Data Science, UniversitÃ¤tslehrgang Data Science*\n",
    "\n",
    "**Date: November 21, 2020**\n",
    "\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "For the practice session, we are going to use the `adversarial-robustness-toolbox` (ART) package, which can be installed via `pip install adversarial-robustness-toolbox[pytorch]`.\n",
    "\n",
    "ART is a Python library for machine learning security. It provides a broad set of tools to defend and evaluate machine learning models. It covers adversarial threats like evasion, poisoning, extraction and inference attacks as well as suitable defenses. It supports all popular machine learning frameworks.\n",
    "\n",
    "Today we will use ART in combination with **PyTorch**. We will explosre some common evasion attacks and demonstrate how ART's defense tools can be used.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "The notebook requires some dependencies, which are found in `requirements.txt`. If you haven't installed them yet, please do this now by running the next cell and restarting the notebook afterwards.\n",
    "\n",
    "We recommend that you run the notebook in an virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Agenda:**\n",
    "\n",
    "1. Initialize Perfect-Knowledge Setting\n",
    "1. Evasion attacks\n",
    " 1. Fast Gradient Sign Method\n",
    " 1. Projected Gradient Descent\n",
    " 1. Carlini and Wagner $l_2$ attack\n",
    "1. Spatial Smoothing Defense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Perfect-Knowledge Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from art.utils import ART_DATA_PATH\n",
    "from art.utils import get_file\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "# disable an annoying depcreation warning that is due to latest ipython\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# download imagenet class index\n",
    "imagenet_labels_uri = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "imagenet_labels_path = get_file(\"imagenet_class_index.json\", imagenet_labels_uri)\n",
    "\n",
    "with open(imagenet_labels_path, \"r\") as f:\n",
    "    IMAGENET_CLASS_INDEX = json.load(f)\n",
    "    \n",
    "# return label name for label index\n",
    "def label_name(label_id: int) -> str:\n",
    "    return IMAGENET_CLASS_INDEX[str(label_id)][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are mounting our attacks on a ResNet-50 model that is trained on the ImageNet dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pretrained ResNet-50 model\n",
    "resnet = models.resnet50(pretrained=True, progress=True)\n",
    "\n",
    "# define appropriate model loss\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GitHub repositoy [imagenet-stubs](https://github.com/nottombrown/imagenet-stubs/raw/master/imagenet_stubs/images/) hosts a selection of ImageNet samples. We choose the Koala sample and download it. \n",
    "\n",
    "PyTorch's model zoo (`torchvision.models`) offers some guidance how the ImageNet samples are to be preprocessed. The following steps are required:\n",
    "\n",
    "* Load image in to a range of `[0,1]`.\n",
    "* Standardize the sample with a mean of `(0.485, 0.456, 0.406)` and standard deviation of `(0.229, 0.224, 0.225)`.\n",
    "* Resize image to `256x256` and center crop to `224x224`.\n",
    "* Transform image shape to `(batch_size, channels, height, width)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download test image\n",
    "test_image_path = get_file(\"koala.jpg\", \n",
    "                           \"https://github.com/nottombrown/imagenet-stubs/raw/master/imagenet_stubs/images/koala.jpg\")\n",
    "# test_image_path = get_file(\"gazelle.jpg\", \n",
    "#                            \"https://github.com/nottombrown/imagenet-stubs/raw/master/imagenet_stubs/images/gazelle.jpg\")\n",
    "# test_image_path = get_file(\"tractor.jpg\", \n",
    "#                            \"https://github.com/nottombrown/imagenet-stubs/raw/master/imagenet_stubs/images/tractor.jpg\")\n",
    "\n",
    "# define imagenet mean and standard deviation\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "# resisze to 256x256\n",
    "img = Image.open(test_image_path)\n",
    "img_resized = img.resize((256, 256), Image.ANTIALIAS)\n",
    "\n",
    "# center crop to 224x224\n",
    "def crop_img(img, height, width):\n",
    "    \"Resize image to (256, 256) and center crop to (height, width).\"\n",
    "    img_resized = img.resize((256, 256), Image.ANTIALIAS)\n",
    "\n",
    "    orig_w, orig_h = img_resized.size\n",
    "    left = (orig_w - width) // 2\n",
    "    top = (orig_h - height) // 2\n",
    "    right = (orig_w + width) // 2\n",
    "    bottom = (orig_h + height) // 2\n",
    "    return img.crop((left, top, right, bottom))\n",
    "img_cropped = crop_img(img_resized, 224, 224)\n",
    "\n",
    "# convert image to normalized np.ndarray \n",
    "x = np.array(img_cropped, dtype=np.float32) / 255\n",
    "\n",
    "# standardize image\n",
    "x_preprocessed = (x - imagenet_mean) / imagenet_std\n",
    "\n",
    "# batchify image and \n",
    "x_batch = np.expand_dims(np.transpose(x_preprocessed, (2, 0, 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now all our compoments at hands that are required for a perfect-knowledge attack. Remember, that we require\n",
    "\n",
    "* knowledge over the model $f$ and weights $\\mathbf{w}$\n",
    "* knowledge of the feature space and training data\n",
    "\n",
    "Now, we can set up a ART classification estimator, which serves as the main interface for the evasion attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?PyTorchClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define ART classification estimator\n",
    "model = PyTorchClassifier(\n",
    "    resnet,\n",
    "    loss,\n",
    "    (1, 3, 224, 224),\n",
    "    nb_classes=1000,\n",
    "    channels_first=True\n",
    ")\n",
    "\n",
    "# test estimator\n",
    "print(f\"Prediction original: {label_name(np.argmax(model.predict(x_batch)))} ({1 / (1 + np.exp(-np.max(model.predict(x_batch))))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evasion attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent, CarliniL2Method\n",
    "from art.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Gradient Sign Method\n",
    "\n",
    "Let's apply an untargeted FGSM attack now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?FastGradientMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm = FastGradientMethod(\n",
    "    estimator=model,\n",
    "    norm=np.inf,\n",
    "    targeted=False,\n",
    "    eps=70/255,\n",
    "    eps_step=1/255,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "x_adv = fgsm.generate(x_batch, y=None)\n",
    "\n",
    "print(f\"Prediction adversarial: {label_name(np.argmax(model.predict(x_adv)))} ({1 / (1 + np.exp(-np.max(model.predict(x_adv))))})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv_unnormalized = np.clip(np.transpose(np.squeeze(x_adv) , (1, 2, 0)) * imagenet_std + imagenet_mean, 0, 1)\n",
    "\n",
    "print(f\"Min pixel: {x_adv_unnormalized.min()}\")\n",
    "print(f\"Max pixel: {x_adv_unnormalized.max()}\")\n",
    "\n",
    "plt.imshow(x_adv_unnormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, let's  implement the FGSM method ourselvs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Try-yourself 2 #\n",
    "##################\n",
    "\n",
    "# Note: no need to change anything in this cell\n",
    "\n",
    "# create device tensor for x_batch\n",
    "x_tensor = torch.Tensor(x_batch)\n",
    "x_tensor.requires_grad = True\n",
    "\n",
    "# calculate loss for (x, y_true) pair\n",
    "loss_tensor = loss(resnet(x_tensor), torch.LongTensor([105]))\n",
    "\n",
    "# calculate gradients of loss at x_tensor\n",
    "resnet.zero_grad()\n",
    "loss_tensor.backward()\n",
    "grad = x_tensor.grad.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do: Apply the FGSM formula (x_adv_self = ...  +  ...)\n",
    "x_adv_self = \n",
    "\n",
    "# To-Do: Undo the standardization\n",
    "x_adv_self_unnormalized = \n",
    "\n",
    "# To-Do: Project the adversarial in the original, unnormalized input space\n",
    "x_adv_self_unnormalized = np.clip()\n",
    "\n",
    "# Bonus: if you have time, try to adapt the code for a targeted attack! Hints:\n",
    "#        * print IMAGENET_CLASS_INDEX and choose a target label index\n",
    "#        * replace the label index (105) in the loss_tensor variable\n",
    "#        * remember that in the targeted variant we want to minimize the loss. What are the\n",
    "#          consequences thereof?\n",
    "#        * is FGSM strong enough to succeed?\n",
    "\n",
    "print(f\"Prediction adversarial: {label_name(np.argmax(model.predict(x_adv_self)))} ({1 / (1 + np.exp(-np.max(model.predict(x_adv_self))))})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min pixel: {x_adv_self_unnormalized.min()}\")\n",
    "print(f\"Max pixel: {x_adv_self_unnormalized.max()}\")\n",
    "\n",
    "plt.imshow(x_adv_self_unnormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected Gradient Descent\n",
    "\n",
    "Let's apply an targeted Projected Gradient Descent attack now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ProjectedGradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Imagenet class index:\")\n",
    "# [print(f\"\\t{idx} -> {label_lst[-1]}\") for idx, label_lst in IMAGENET_CLASS_INDEX.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd = ProjectedGradientDescent(\n",
    "    estimator=model,\n",
    "    norm=np.inf,\n",
    "    targeted=True,\n",
    "    eps=5/255,\n",
    "    eps_step=1/255,\n",
    "    max_iter=1,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "y_target = to_categorical([285], nb_classes=1000) \n",
    "x_adv = pgd.generate(x_batch, y=y_target)\n",
    "\n",
    "print(f\"Target label: {label_name(285)}\")\n",
    "print(f\"Prediction adversarial: {label_name(np.argmax(model.predict(x_adv)))} ({1 / (1 + np.exp(-np.max(model.predict(x_adv))))})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv_unnormalized = np.clip(np.transpose(np.squeeze(x_adv) , (1, 2, 0)) * imagenet_std + imagenet_mean, 0, 1)\n",
    "\n",
    "print(f\"Min pixel: {x_adv_unnormalized.min()}\")\n",
    "print(f\"Max pixel: {x_adv_unnormalized.max()}\")\n",
    "\n",
    "plt.imshow(x_adv_unnormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try to make our previous FGSM iterative and project the perturbation $\\delta$ on the $l_\\infty$-ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Try-yourself 2 #\n",
    "##################\n",
    "\n",
    "# define\n",
    "x_torch_orig = torch.from_numpy(x_batch)\n",
    "x_torch_adv = torch.from_numpy(x_batch)\n",
    "\n",
    "# try to run multiple iterations. What's the smallest number of iterations you need?\n",
    "for i in range(6):\n",
    "    # we require gradients for the attack\n",
    "    x_torch_adv.requires_grad = True\n",
    "\n",
    "    # To-Do: calculate loss for (x, y_true) pair (tip: check some of the previous cells)\n",
    "    loss_tensor = \n",
    "    \n",
    "    # zero gradients\n",
    "    resnet.zero_grad()\n",
    "\n",
    "    # backward pass on loss\n",
    "    loss_tensor.backward()\n",
    "    \n",
    "    # get gradients\n",
    "    grad = x_torch_adv.grad.data\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # To-Do: peform a gradient descent step with step size of 1/255\n",
    "        x_torch_adv =\n",
    "        \n",
    "        # To-Do: clip perturbation delta at 5/255\n",
    "        delta = torch.clip()\n",
    "        \n",
    "        # re-apply delta to original example\n",
    "        x_torch_adv = x_torch_orig + delta\n",
    "\n",
    "# save adversarial as numpy array        \n",
    "x_adv = x_torch_adv.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Target label: {label_name(285)}\")\n",
    "print(f\"Prediction adversarial: {label_name(np.argmax(model.predict(x_adv)))} ({1 / (1 + np.exp(-np.max(model.predict(x_adv))))})\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carlini and Wagner $l_2$ attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?CarliniL2Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = CarliniL2Method(\n",
    "    classifier=model,\n",
    "    targeted=True,\n",
    "    confidence=0.0,\n",
    "    max_iter=10,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "y_target = to_categorical([285], nb_classes=1000) \n",
    "x_adv = cw.generate(x_batch, y=y_target)\n",
    "\n",
    "print(f\"Target label: {label_name(285)}\")\n",
    "print(f\"Prediction adversarial: {label_name(np.argmax(model.predict(x_adv)))} ({1 / (1 + np.exp(-np.max(model.predict(x_adv))))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Smoothing Defense\n",
    "\n",
    "ART also provides a set of defenses. Namely, pre- and postprocessing defenses as well as adversarial training. We will use the spatial smoothing defense and try to circumvent it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.defences.preprocessor import SpatialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define spatial smoothing defense\n",
    "defense = SpatialSmoothing(window_size=3)\n",
    "\n",
    "# re-generate adversarial example with PGD\n",
    "pgd = ProjectedGradientDescent(\n",
    "    estimator=model,\n",
    "    norm=np.inf,\n",
    "    targeted=True,\n",
    "    eps=5/255,\n",
    "    eps_step=1/255,\n",
    "    max_iter=20,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "y_target = to_categorical([285], nb_classes=1000) \n",
    "x_adv = pgd.generate(x_batch, y=y_target)\n",
    "\n",
    "# apply defense to original and adversarial example\n",
    "x_batch_defense, _ = defense(x_batch)\n",
    "x_adv_defense, _ = defense(x_adv)\n",
    "\n",
    "print(f\"Target label: {label_name(285)}\")\n",
    "print(f\"Prediction adversarial: {label_name(np.argmax(model.predict(x_adv)))} ({1 / (1 + np.exp(-np.max(model.predict(x_adv))))})\")\n",
    "print(f\"Prediction original after defense: {label_name(np.argmax(model.predict(x_batch_defense)))} ({1 / (1 + np.exp(-np.max(model.predict(x_batch_defense))))})\")\n",
    "print(f\"Prediction adversarial after defense: {label_name(np.argmax(model.predict(x_adv_defense)))} ({1 / (1 + np.exp(-np.max(model.predict(x_adv_defense))))})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv_defense_unnormalized = np.clip(np.transpose(np.squeeze(x_adv_defense) , (1, 2, 0)) * imagenet_std + imagenet_mean, 0, 1)\n",
    "\n",
    "print(f\"Min pixel: {x_adv_defense_unnormalized.min()}\")\n",
    "print(f\"Max pixel: {x_adv_defense_unnormalized.max()}\")\n",
    "\n",
    "plt.imshow(x_adv_defense_unnormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to employ an adaptive whitebox attack to defeat the spatial smoothing defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Try-yourself 3 #\n",
    "##################\n",
    "\n",
    "# define spatial smoothing defense\n",
    "defense = SpatialSmoothing(window_size=3)\n",
    "\n",
    "# define adaptive classifier\n",
    "model_adaptive = PyTorchClassifier(\n",
    "    resnet,\n",
    "    loss,\n",
    "    (1, 3, 224, 224),\n",
    "    nb_classes=1000,\n",
    "    channels_first=True,\n",
    "    # To-Do: Have a look a the documentation. What possible argument could be useful?\n",
    "    # ...\n",
    ")\n",
    "\n",
    "\n",
    "# re-generate adversarial example with PGD\n",
    "pgd_adaptive = ProjectedGradientDescent(\n",
    "    estimator=model_adaptive,\n",
    "    norm=np.inf,\n",
    "    targeted=True,\n",
    "    eps=5/255,\n",
    "    eps_step=1/255,\n",
    "    batch_size=1,\n",
    "    # To-Do: Play around with max_iter. How many iterations are required?\n",
    "    max_iter=1,\n",
    ")\n",
    "\n",
    "y_target = to_categorical([285], nb_classes=1000) \n",
    "x_adv_adaptive = pgd_adaptive.generate(x_batch, y=y_target)\n",
    "\n",
    "print(f\"Target label: {label_name(285)}\")\n",
    "print(f\"Prediction adversarial adaptive: {label_name(np.argmax(model_adaptive.predict(x_adv_adaptive)))} ({1 / (1 + np.exp(-np.max(model_adaptive.predict(x_adv_adaptive))))})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv_adaptive_unnormalized = np.clip(np.transpose(np.squeeze(x_adv_adaptive) , (1, 2, 0)) * imagenet_std + imagenet_mean, 0, 1)\n",
    "\n",
    "print(f\"Min pixel: {x_adv_adaptive_unnormalized.min()}\")\n",
    "print(f\"Max pixel: {x_adv_adaptive_unnormalized.max()}\")\n",
    "\n",
    "plt.imshow(x_adv_adaptive_unnormalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
